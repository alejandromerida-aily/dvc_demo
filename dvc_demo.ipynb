{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       569 non-null    float64\n",
      " 1   1       569 non-null    float64\n",
      " 2   2       569 non-null    float64\n",
      " 3   3       569 non-null    float64\n",
      " 4   4       569 non-null    float64\n",
      " 5   5       569 non-null    float64\n",
      " 6   6       569 non-null    float64\n",
      " 7   7       569 non-null    float64\n",
      " 8   8       569 non-null    float64\n",
      " 9   9       569 non-null    float64\n",
      " 10  10      569 non-null    float64\n",
      " 11  11      569 non-null    float64\n",
      " 12  12      569 non-null    float64\n",
      " 13  13      569 non-null    float64\n",
      " 14  14      569 non-null    float64\n",
      " 15  15      569 non-null    float64\n",
      " 16  16      569 non-null    float64\n",
      " 17  17      569 non-null    float64\n",
      " 18  18      569 non-null    float64\n",
      " 19  19      569 non-null    float64\n",
      " 20  20      569 non-null    float64\n",
      " 21  21      569 non-null    float64\n",
      " 22  22      569 non-null    float64\n",
      " 23  23      569 non-null    float64\n",
      " 24  24      569 non-null    float64\n",
      " 25  25      569 non-null    float64\n",
      " 26  26      569 non-null    float64\n",
      " 27  27      569 non-null    float64\n",
      " 28  28      569 non-null    float64\n",
      " 29  29      569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(data.data)\n",
    "\n",
    "y = data.target\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>10.710</td>\n",
       "      <td>20.39</td>\n",
       "      <td>69.50</td>\n",
       "      <td>344.9</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>0.02867</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.06862</td>\n",
       "      <td>...</td>\n",
       "      <td>11.69</td>\n",
       "      <td>25.21</td>\n",
       "      <td>76.51</td>\n",
       "      <td>410.4</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.25340</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.08701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>9.876</td>\n",
       "      <td>19.40</td>\n",
       "      <td>63.95</td>\n",
       "      <td>298.3</td>\n",
       "      <td>0.10050</td>\n",
       "      <td>0.09697</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>...</td>\n",
       "      <td>10.76</td>\n",
       "      <td>26.83</td>\n",
       "      <td>72.22</td>\n",
       "      <td>361.2</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>0.26440</td>\n",
       "      <td>0.09749</td>\n",
       "      <td>0.2622</td>\n",
       "      <td>0.08490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>9.731</td>\n",
       "      <td>15.34</td>\n",
       "      <td>63.78</td>\n",
       "      <td>300.2</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.07857</td>\n",
       "      <td>0.2548</td>\n",
       "      <td>0.09296</td>\n",
       "      <td>...</td>\n",
       "      <td>11.02</td>\n",
       "      <td>19.49</td>\n",
       "      <td>71.04</td>\n",
       "      <td>380.5</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.82160</td>\n",
       "      <td>0.15710</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.12590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>11.470</td>\n",
       "      <td>16.03</td>\n",
       "      <td>73.02</td>\n",
       "      <td>402.7</td>\n",
       "      <td>0.09076</td>\n",
       "      <td>0.05886</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>0.02322</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.06372</td>\n",
       "      <td>...</td>\n",
       "      <td>12.51</td>\n",
       "      <td>20.79</td>\n",
       "      <td>79.67</td>\n",
       "      <td>475.8</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.06548</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>0.08763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>9.295</td>\n",
       "      <td>13.90</td>\n",
       "      <td>59.96</td>\n",
       "      <td>257.8</td>\n",
       "      <td>0.13710</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.033320</td>\n",
       "      <td>0.02421</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.07696</td>\n",
       "      <td>...</td>\n",
       "      <td>10.57</td>\n",
       "      <td>17.84</td>\n",
       "      <td>67.84</td>\n",
       "      <td>326.6</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.2097</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07262</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>0.08982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.03890</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.06341</td>\n",
       "      <td>...</td>\n",
       "      <td>16.22</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.4202</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>15.190</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.033930</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>15.530</td>\n",
       "      <td>33.56</td>\n",
       "      <td>103.70</td>\n",
       "      <td>744.9</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.08399</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>0.06650</td>\n",
       "      <td>...</td>\n",
       "      <td>18.49</td>\n",
       "      <td>49.54</td>\n",
       "      <td>126.30</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>0.5564</td>\n",
       "      <td>0.57030</td>\n",
       "      <td>0.20140</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>0.12040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>10.160</td>\n",
       "      <td>19.59</td>\n",
       "      <td>64.73</td>\n",
       "      <td>311.7</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.07504</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.01116</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.06331</td>\n",
       "      <td>...</td>\n",
       "      <td>10.65</td>\n",
       "      <td>22.88</td>\n",
       "      <td>67.88</td>\n",
       "      <td>347.3</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.06742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>11.060</td>\n",
       "      <td>14.96</td>\n",
       "      <td>71.49</td>\n",
       "      <td>373.9</td>\n",
       "      <td>0.10330</td>\n",
       "      <td>0.09097</td>\n",
       "      <td>0.053970</td>\n",
       "      <td>0.03341</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.06907</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>19.90</td>\n",
       "      <td>79.76</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.22990</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.09080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2      3        4        5         6        7   \\\n",
       "269  10.710  20.39   69.50  344.9  0.10820  0.12890  0.084480  0.02867   \n",
       "103   9.876  19.40   63.95  298.3  0.10050  0.09697  0.061540  0.03029   \n",
       "152   9.731  15.34   63.78  300.2  0.10720  0.15990  0.410800  0.07857   \n",
       "348  11.470  16.03   73.02  402.7  0.09076  0.05886  0.025870  0.02322   \n",
       "520   9.295  13.90   59.96  257.8  0.13710  0.12250  0.033320  0.02421   \n",
       "..      ...    ...     ...    ...      ...      ...       ...      ...   \n",
       "541  14.470  24.99   95.81  656.4  0.08837  0.12300  0.100900  0.03890   \n",
       "371  15.190  13.21   97.65  711.8  0.07963  0.06934  0.033930  0.02657   \n",
       "259  15.530  33.56  103.70  744.9  0.10630  0.16390  0.175100  0.08399   \n",
       "556  10.160  19.59   64.73  311.7  0.10030  0.07504  0.005025  0.01116   \n",
       "342  11.060  14.96   71.49  373.9  0.10330  0.09097  0.053970  0.03341   \n",
       "\n",
       "         8        9   ...     20     21      22      23      24      25  \\\n",
       "269  0.1668  0.06862  ...  11.69  25.21   76.51   410.4  0.1335  0.2550   \n",
       "103  0.1945  0.06322  ...  10.76  26.83   72.22   361.2  0.1559  0.2302   \n",
       "152  0.2548  0.09296  ...  11.02  19.49   71.04   380.5  0.1292  0.2772   \n",
       "348  0.1634  0.06372  ...  12.51  20.79   79.67   475.8  0.1531  0.1120   \n",
       "520  0.2197  0.07696  ...  10.57  17.84   67.84   326.6  0.1850  0.2097   \n",
       "..      ...      ...  ...    ...    ...     ...     ...     ...     ...   \n",
       "541  0.1872  0.06341  ...  16.22  31.73  113.50   808.9  0.1340  0.4202   \n",
       "371  0.1721  0.05544  ...  16.20  15.73  104.50   819.1  0.1126  0.1737   \n",
       "259  0.2091  0.06650  ...  18.49  49.54  126.30  1035.0  0.1883  0.5564   \n",
       "556  0.1791  0.06331  ...  10.65  22.88   67.88   347.3  0.1265  0.1200   \n",
       "342  0.1776  0.06907  ...  11.92  19.90   79.76   440.0  0.1418  0.2210   \n",
       "\n",
       "          26       27      28       29  \n",
       "269  0.25340  0.08600  0.2605  0.08701  \n",
       "103  0.26440  0.09749  0.2622  0.08490  \n",
       "152  0.82160  0.15710  0.3108  0.12590  \n",
       "348  0.09823  0.06548  0.2851  0.08763  \n",
       "520  0.09996  0.07262  0.3681  0.08982  \n",
       "..       ...      ...     ...      ...  \n",
       "541  0.40400  0.12050  0.3187  0.10230  \n",
       "371  0.13620  0.08178  0.2487  0.06766  \n",
       "259  0.57030  0.20140  0.3512  0.12040  \n",
       "556  0.01005  0.02232  0.2262  0.06742  \n",
       "342  0.22990  0.10750  0.3301  0.09080  \n",
       "\n",
       "[398 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dvclive:Can't save experiment to an empty Git Repo.\n",
      "Add a commit (`git commit`) to save experiments.\n",
      "WARNING:dvclive:Can't save experiment to an empty Git Repo.\n",
      "Add a commit (`git commit`) to save experiments.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# DVC Report\n",
       "\n",
       "metrics.json\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dvclive:Can't save experiment to an empty Git Repo.\n",
      "Add a commit (`git commit`) to save experiments.\n",
      "WARNING:dvclive:Can't save experiment to an empty Git Repo.\n",
      "Add a commit (`git commit`) to save experiments.\n",
      "[I 2023-11-20 17:07:56,011] A new study created in memory with name: no-name-41f88023-8893-4aac-8aa1-e2051d333723\n",
      "[W 2023-11-20 17:07:56,014] Trial 0 failed with parameters: {'n_estimators': 94, 'max_depth': 21, 'learning_rate': 0.32862629464594134} because of the following error: TypeError(\"'XGBClassifier' object is not callable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alejandromeridamaroto/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 313, in <lambda>\n",
      "    objective_with_data = lambda trial: self._objective(\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 224, in _objective\n",
      "    clf = self.classifier(**param_values)\n",
      "TypeError: 'XGBClassifier' object is not callable\n",
      "[W 2023-11-20 17:07:56,017] Trial 0 failed with value None.\n",
      "[W 2023-11-20 17:07:56,015] Trial 2 failed with parameters: {'n_estimators': 181, 'max_depth': 7, 'learning_rate': 0.5000242643030426} because of the following error: TypeError(\"'XGBClassifier' object is not callable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alejandromeridamaroto/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 313, in <lambda>\n",
      "    objective_with_data = lambda trial: self._objective(\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 224, in _objective\n",
      "    clf = self.classifier(**param_values)\n",
      "TypeError: 'XGBClassifier' object is not callable\n",
      "[W 2023-11-20 17:07:56,017] Trial 3 failed with parameters: {'n_estimators': 70, 'max_depth': 30, 'learning_rate': 0.591394389114989} because of the following error: TypeError(\"'XGBClassifier' object is not callable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alejandromeridamaroto/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 313, in <lambda>\n",
      "    objective_with_data = lambda trial: self._objective(\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 224, in _objective\n",
      "    clf = self.classifier(**param_values)\n",
      "TypeError: 'XGBClassifier' object is not callable\n",
      "[W 2023-11-20 17:07:56,017] Trial 4 failed with parameters: {'n_estimators': 94, 'max_depth': 14, 'learning_rate': 0.6536058288472184} because of the following error: TypeError(\"'XGBClassifier' object is not callable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alejandromeridamaroto/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 313, in <lambda>\n",
      "    objective_with_data = lambda trial: self._objective(\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 224, in _objective\n",
      "    clf = self.classifier(**param_values)\n",
      "TypeError: 'XGBClassifier' object is not callable\n",
      "[W 2023-11-20 17:07:56,015] Trial 1 failed with parameters: {'n_estimators': 94, 'max_depth': 10, 'learning_rate': 0.31779103246103474} because of the following error: TypeError(\"'XGBClassifier' object is not callable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alejandromeridamaroto/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 313, in <lambda>\n",
      "    objective_with_data = lambda trial: self._objective(\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 224, in _objective\n",
      "    clf = self.classifier(**param_values)\n",
      "TypeError: 'XGBClassifier' object is not callable\n",
      "[W 2023-11-20 17:07:56,018] Trial 5 failed with parameters: {'n_estimators': 91, 'max_depth': 6, 'learning_rate': 0.24695545283450912} because of the following error: TypeError(\"'XGBClassifier' object is not callable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alejandromeridamaroto/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 313, in <lambda>\n",
      "    objective_with_data = lambda trial: self._objective(\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 224, in _objective\n",
      "    clf = self.classifier(**param_values)\n",
      "TypeError: 'XGBClassifier' object is not callable\n",
      "[W 2023-11-20 17:07:56,019] Trial 6 failed with parameters: {'n_estimators': 92, 'max_depth': 35, 'learning_rate': 0.9287405249569561} because of the following error: TypeError(\"'XGBClassifier' object is not callable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alejandromeridamaroto/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 313, in <lambda>\n",
      "    objective_with_data = lambda trial: self._objective(\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 224, in _objective\n",
      "    clf = self.classifier(**param_values)\n",
      "TypeError: 'XGBClassifier' object is not callable\n",
      "[W 2023-11-20 17:07:56,020] Trial 7 failed with parameters: {'n_estimators': 59, 'max_depth': 25, 'learning_rate': 0.791231214426982} because of the following error: TypeError(\"'XGBClassifier' object is not callable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alejandromeridamaroto/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 313, in <lambda>\n",
      "    objective_with_data = lambda trial: self._objective(\n",
      "  File \"/Users/alejandromeridamaroto/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py\", line 224, in _objective\n",
      "    clf = self.classifier(**param_values)\n",
      "TypeError: 'XGBClassifier' object is not callable\n",
      "[W 2023-11-20 17:07:56,020] Trial 2 failed with value None.\n",
      "[W 2023-11-20 17:07:56,021] Trial 3 failed with value None.\n",
      "[W 2023-11-20 17:07:56,021] Trial 4 failed with value None.\n",
      "[W 2023-11-20 17:07:56,022] Trial 1 failed with value None.\n",
      "[W 2023-11-20 17:07:56,023] Trial 5 failed with value None.\n",
      "[W 2023-11-20 17:07:56,023] Trial 6 failed with value None.\n",
      "[W 2023-11-20 17:07:56,024] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'XGBClassifier' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 64\u001b[0m\n\u001b[1;32m     47\u001b[0m     fixed_param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m     48\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mbinary:logistic\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     49\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mverbosity\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m,\n\u001b[1;32m     50\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mearly_stopping_rounds\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m\n\u001b[1;32m     51\u001b[0m }\n\u001b[1;32m     52\u001b[0m     optimizer \u001b[39m=\u001b[39m OptunaModelOptimizer(\n\u001b[1;32m     53\u001b[0m         classifier\u001b[39m=\u001b[39mclassifier,\n\u001b[1;32m     54\u001b[0m         scoring_metric\u001b[39m=\u001b[39mSCORING,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m         seed\u001b[39m=\u001b[39mSEED\n\u001b[1;32m     62\u001b[0m     )\n\u001b[0;32m---> 64\u001b[0m optimizer\u001b[39m.\u001b[39;49mfit(x_train, y_train, x_test, y_test, n_trials\u001b[39m=\u001b[39;49mN_TRIALS, calculate_metrics\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py:319\u001b[0m, in \u001b[0;36mOptunaModelOptimizer.fit\u001b[0;34m(self, x_train, y_train, x_test, y_test, n_trials, direction, calculate_metrics, n_jobs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# Check if there are conflicting names between parameter grids\u001b[39;00m\n\u001b[1;32m    317\u001b[0m _check_parameter_conflict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed_param_grid)\n\u001b[0;32m--> 319\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudy\u001b[39m.\u001b[39;49moptimize(objective_with_data, n_trials\u001b[39m=\u001b[39;49mn_trials, n_jobs\u001b[39m=\u001b[39;49mn_jobs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py:103\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[39m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m                     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n\u001b[0;32m--> 103\u001b[0m                         f\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    105\u001b[0m                 futures\u001b[39m.\u001b[39madd(\n\u001b[1;32m    106\u001b[0m                     executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m    107\u001b[0m                         _optimize_sequential,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     )\n\u001b[1;32m    119\u001b[0m                 )\n\u001b[1;32m    120\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py:313\u001b[0m, in \u001b[0;36mOptunaModelOptimizer.fit.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39mFit the classifier and optimize hyperparameters.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39m    n_jobs (int): Number of CPU cores to use. The default -1 uses all cores available.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstudy \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[1;32m    311\u001b[0m     direction\u001b[39m=\u001b[39mdirection, sampler\u001b[39m=\u001b[39mTPESampler(seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed)\n\u001b[1;32m    312\u001b[0m )\n\u001b[0;32m--> 313\u001b[0m objective_with_data \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m trial: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_objective(\n\u001b[1;32m    314\u001b[0m     trial, x_train, y_train, x_test, y_test, calculate_metrics\n\u001b[1;32m    315\u001b[0m )\n\u001b[1;32m    316\u001b[0m \u001b[39m# Check if there are conflicting names between parameter grids\u001b[39;00m\n\u001b[1;32m    317\u001b[0m _check_parameter_conflict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed_param_grid)\n",
      "File \u001b[0;32m~/aily/vcs/aily-ai-sanofi/src/lab_capa/src/models/classification/tuner.py:224\u001b[0m, in \u001b[0;36mOptunaModelOptimizer._objective\u001b[0;34m(self, trial, x_train, y_train, x_test, y_test, calculate_metrics)\u001b[0m\n\u001b[1;32m    222\u001b[0m param_values\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed_param_grid)\n\u001b[1;32m    223\u001b[0m \u001b[39m# Create an instance of the classifier with the selected hyperparameters\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m clf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparam_values)\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_folds:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Perform cross-validation and calculate the mean and standard deviation of the\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# target score\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     cross_val_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    230\u001b[0m         clf,\n\u001b[1;32m    231\u001b[0m         x_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m         return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    238\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'XGBClassifier' object is not callable"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score\n",
    "import optuna \n",
    "from dvclive.xgb import DVCLiveCallback\n",
    "from dvclive import Live\n",
    "\n",
    "from models.classification.tuner import OptunaModelOptimizer\n",
    "\n",
    "\n",
    "N_TRIALS = 30\n",
    "SCORING = roc_auc_score\n",
    "SEED = 42\n",
    "\n",
    "tracking_metrics = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"f1\": f1_score,\n",
    "    \"recall\": recall_score,\n",
    "}\n",
    "\n",
    "classifier = xgb.XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 200),\n",
    "    'max_depth': optuna.distributions.IntDistribution(5, 40),\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.01, 1),\n",
    "}\n",
    "\n",
    "\n",
    "fit_params = {\n",
    "    'eval_set':[(x_test, y_test)],\n",
    "    'verbose': False,\n",
    "            }\n",
    "\n",
    "\n",
    "tracking_metrics_params = {\n",
    "                        \"f1\": {\n",
    "                            \"average\":\"binary\"\n",
    "                        },\n",
    "                        \"recall\": {\n",
    "                            \"average\":\"binary\"\n",
    "                        },\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "with Live(str(\"results\"), save_dvc_exp=True, report=\"notebook\") as live:     \n",
    "    fixed_param_grid = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'verbosity': 0,\n",
    "    'early_stopping_rounds': 2,\n",
    "    'callbacks':[DVCLiveCallback()]\n",
    "}\n",
    "    optimizer = OptunaModelOptimizer(\n",
    "        classifier=classifier,\n",
    "        scoring_metric=SCORING,\n",
    "        param_grid=param_grid,\n",
    "        fit_params=fit_params,\n",
    "        fixed_param_grid=fixed_param_grid,\n",
    "        tracking_metrics=tracking_metrics,\n",
    "        tracking_metrics_params=tracking_metrics_params,\n",
    "        cv_folds=4,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "optimizer.fit(x_train, y_train, x_test, y_test, n_trials=N_TRIALS, calculate_metrics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvclive import Live\n",
    "\n",
    "with Live(\"eval\", dvcyaml=False) as live:\n",
    "    if not live.summary:\n",
    "        live.summary = {\"roc_auc\": {}, \"f1-score\": {}, \"accuracy\": {}, \"recall\": {}}\n",
    "    for row, value in df_result.iterrows():\n",
    "        live.summary[\"roc_auc\"][row] = value['user_attrs_scoring_metric_value']\n",
    "        live.summary[\"f1-score\"][row] = value['user_attrs_test_f1']\n",
    "        live.summary[\"accuracy\"][row] = value['user_attrs_test_accuracy']\n",
    "        live.summary[\"recall\"][row] = value['user_attrs_test_recall']\n",
    "\n",
    "live.summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
